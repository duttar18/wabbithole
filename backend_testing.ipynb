{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocklist = [\n",
    "    \"Main_Page\",\n",
    "    \"Help:\",\n",
    "    \"Special:\",\n",
    "    \"Portal:\",\n",
    "    \"Talk:\",\n",
    "    \"Wikipedia:\",\n",
    "    \"Template:\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wiki/Hamilton–Jacobi–Bellman_equation'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.parse.unquote(\"/wiki/Hamilton%E2%80%93Jacobi%E2%80%93Bellman_equation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wiki_link(link):\n",
    "    r = requests.get(link)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    wiki_content_links = set()\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        clean_link = link[\"href\"]\n",
    "        clean_link = urllib.parse.unquote(clean_link)\n",
    "        if clean_link.startswith(\"/wiki/\"):\n",
    "            wiki_link = clean_link[6:]\n",
    "            if any(x in wiki_link for x in blocklist):\n",
    "                continue\n",
    "            wiki_content_links.add(clean_link)\n",
    "    return wiki_content_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://en.wikipedia.org/wiki/Hamilton–Jacobi–Bellman_equation\"\n",
    "l = parse_wiki_link(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserHistory:\n",
    "    def __init__(self, user_visits):\n",
    "        # user_vists is a list of links in chronological order ascending\n",
    "        # user_vists[-1] is the current page\n",
    "        self.outgoing_links = set()\n",
    "        #self.ingoing_links = set()\n",
    "        for link in user_visits:\n",
    "            self.outgoing_links.update(parse_wiki_link(link))\n",
    "            #self.ingoing_links.update(parse_wiki_ingoing(link))\n",
    "        already_visited_pages = {link.split(\"wikipedia.org/\"[1]) for link in user_visits}\n",
    "\n",
    "        # remove self-loops\n",
    "        self.outgoing_links -= already_visited_pages\n",
    "        #self.ingoing_links -= already_visited_pages\n",
    "        \n",
    "        # first stage of ranking: use NLP to choose top-k links from self.outgoing_links\n",
    "        #   Collect text from all pages on user_visits\n",
    "        #   TF-IDF for similarity between (Text in links) and (Text in all pages)\n",
    "        #   For top textually similar links, crawl these target pages for text & links\n",
    "        #       check link similarity (can also use text from the target page now)\n",
    "\n",
    "\n",
    "        # simple baseline: for scoring a link y_t+1 given history y_1, ..., y_t of links\n",
    "        # where the outgoing links included in y_i denoted O_i={x \\in y_i}\n",
    "        # score(y_t+1 | y_0, ..., y_t) = \\sum_i=1^t 1_{y_t+1 \\in O_i && y_t+1 != y_j, j=1,...,t}\n",
    "        # i.e. how many times a link appeared in history pages, but was not itself in the user history\n",
    "        #   problem: what about links like ISBN? Links on every page which are not interesting\n",
    "        \n",
    "        # simple baseline+1: composite the frequency scoring with textual similarity between text in link\n",
    "        # and text in history of pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_by_link(user_history):\n",
    "    # user_history  \n",
    "    #   incorporate idf\n",
    "    #   incorporate ingoing recommendations\n",
    "    # return dictionary with (key,val)=(link, score)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_by_link_text(user_history):\n",
    "    # user_history  \n",
    "    #   incorporate idf\n",
    "    #   incorporate ingoing recommendations\n",
    "    # return dictionary with (key,val)=(link, score)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_by_coupling(user_history, base_scores):\n",
    "    # user_history  \n",
    "    #   re-rank previous results\n",
    "    # return dictionary with (key,val)=(link, score)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_history(user_history):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7fe94ad52fb42cd2c8480166949ec48c6429ac5eb7e0959789098eed3674765"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('ml_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
