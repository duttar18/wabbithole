{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocklist = [\n",
    "    \"Main_Page\",\n",
    "    \"Help:\",\n",
    "    \"Special:\",\n",
    "    \"Portal:\",\n",
    "    \"Talk:\",\n",
    "    \"Wikipedia:\",\n",
    "    \"Template:\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/wiki/Hamilton–Jacobi–Bellman_equation'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.parse.unquote(\"/wiki/Hamilton%E2%80%93Jacobi%E2%80%93Bellman_equation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wiki_link(link):\r\n",
    "    r = requests.get(link)\r\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\r\n",
    "\r\n",
    "\r\n",
    "# dont look if wrapper class is cite\r\n",
    "    wiki_content_links = set()\r\n",
    "    for link in soup.find_all('a', href=True):\r\n",
    "        if link[\"href\"] == \"#cite_ref-1\":\r\n",
    "            break\r\n",
    "        clean_link = link[\"href\"]\r\n",
    "        clean_link = urllib.parse.unquote(clean_link)\r\n",
    "        if clean_link.startswith(\"/wiki/\"):\r\n",
    "            wiki_link = clean_link[6:]\r\n",
    "            if any(x in wiki_link for x in blocklist):\r\n",
    "                continue\r\n",
    "            wiki_content_links.add(clean_link)\r\n",
    "    return wiki_content_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://en.wikipedia.org/wiki/Hamilton–Jacobi–Bellman_equation\"\n",
    "l = parse_wiki_link(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/wiki/Value_function', '/wiki/Elliptic_partial_differential_equation', '/wiki/Taylor_expansion', '/wiki/Rudolf_E._Kálmán', '/wiki/Sum-of-squares_optimization', '/wiki/Michael_G._Crandall', '/wiki/Artificial_neural_network', '/wiki/Control_(optimal_control_theory)', '/wiki/Classical_physics', '/wiki/Bequest_value', '/wiki/Itô_calculus', '/wiki/Minimax_solution', '/wiki/Partial_differential_equation', \"/wiki/Pontryagin's_maximum_principle\", '/wiki/Discrete_time_and_continuous_time', '/wiki/Linear-quadratic-Gaussian_control', '/wiki/Necessary_and_sufficient_condition', '/wiki/Richard_Bellman', '/wiki/Hamilton–Jacobi_equation', '/wiki/Riccati_equation', '/wiki/Difference_equation', '/wiki/Infinitesimal_generator_(stochastic_processes)', '/wiki/Hamiltonian_(control_theory)', '/wiki/Smoothness', '/wiki/Variational_problem', '/wiki/Optimal_control_theory', '/wiki/Brachistochrone_problem', '/wiki/Subderivative', '/wiki/Pierre-Louis_Lions', '/wiki/Backward_induction', '/wiki/Bellman_equation', '/wiki/John_Tsitsiklis', '/wiki/Loss_function', \"/wiki/Merton's_portfolio_problem\", '/wiki/Dimitri_Bertsekas', '/wiki/Viscosity_solution', '/wiki/Stochastic', '/wiki/Principle_of_optimality', '/wiki/Dynamic_programming', '/wiki/Little-o_notation', '/wiki/Multilayer_perceptron'}\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserHistory:\r\n",
    "    def __init__(self, user_history):\r\n",
    "        self.user_history = user_history\r\n",
    "        # user_vists is a list of links in chronological order ascending\r\n",
    "        # user_vists[-1] is the current page\r\n",
    "        self.outgoing_links = set() # TODO change this to dict() : key -> count\r\n",
    "        #self.ingoing_links = set()\r\n",
    "        for link in user_history:\r\n",
    "            self.outgoing_links.update(parse_wiki_link(link))\r\n",
    "            #self.ingoing_links.update(parse_wiki_ingoing(link))\r\n",
    "        already_visited_pages = {link.split(\"wikipedia.org/\"[1]) for link in user_history}\r\n",
    "        self.current_link = user_history[-1]\r\n",
    "\r\n",
    "        # remove self-loops\r\n",
    "        self.outgoing_links -= already_visited_pages # for k in already_visited_pages: remove\r\n",
    "        #self.ingoing_links -= already_visited_pages\r\n",
    "        \r\n",
    "        # self.outgoing_text\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_link_similarity(user_history, target):\n",
    "    # user_history  \n",
    "    #   incorporate idf (just hyperlinks) -> scrape target/what_links_here (expensive)\n",
    "    #   or sample 10000 pages and count link frequency and store it somewhere else                       \n",
    "    #   incorporate ingoing recommendations\n",
    "    # return score(target | user_history)\n",
    "\n",
    "    # how many times does target appear in self.outgoing_links\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_clean(target):\r\n",
    "    title = target.lower()\r\n",
    "    title = title[6:]\r\n",
    "    title = title.replace(\"_\", \" \")\r\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_link_text_similarity(user_history, target):\r\n",
    "    # user_history  \r\n",
    "    #   incorporate idf (text)\r\n",
    "    #   incorporate ingoing recommendations\r\n",
    "    # return score(target | user_history)\r\n",
    "\r\n",
    "    # references in div class = reflist\r\n",
    "    \r\n",
    "    target = link_clean(target)\r\n",
    "    r = requests.get(user_history[-1])\r\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\r\n",
    "    words = soup.find_all('p')\r\n",
    "    total = 0\r\n",
    "    for i in words:\r\n",
    "        i = str(i)\r\n",
    "        i = i.lower()\r\n",
    "        total += i.count(target)\r\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_link_text_similarity([link], '/wiki/ISBN_(identifier)')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_coupling_similarity(user_history, target):\n",
    "    # user_history  \n",
    "    #   need to download target and scrape it's links\n",
    "    # pages are similar if their outgoing (ingoing) links have overlap\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_outgoing_scores_baseline(user_history):\n",
    "    # composite score_link_similarity and score_link_text_similarity\n",
    "    # (todo: this filters scores, will do re-ranking with coupling similarity, re-ranking with deeper searches, etc)\n",
    "    weight = 1.0 # to be tuned\n",
    "    outgoing_scores = dict()\n",
    "    for link in user_history.outgoing_links:\n",
    "        outgoing_scores[link] = score_link_similarity(user_history, link) + weight * score_link_text_similarity(user_history, link)\n",
    "    return outgoing_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-92-8676a6193530>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-92-8676a6193530>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def rerank_with_coupling(user_history, baseline_scores):\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def rerank_with_coupling(user_history, baseline_scores, num_rerank):\n",
    "    sorted_scores = sort(baseline_scores, 'descending')\n",
    "\n",
    "    for target, score in sorted_scores[num_rerank]:\n",
    "        coupling_score = score_coupling_similarity(user_history, target)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(ranks):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_history(user_history):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {},
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}