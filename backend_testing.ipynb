{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import numpy as np\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocklist = [\n",
    "    \"Main_Page\",\n",
    "    \"Help:\",\n",
    "    \"Special:\",\n",
    "    \"Portal:\",\n",
    "    \"Talk:\",\n",
    "    \"Template:\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wiki_link(link, get_text=False):\n",
    "    r = requests.get(link)\n",
    "    \n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    # jank way to figure out redirect links\n",
    "    real_link = soup.find_all('link', {\"rel\" : \"canonical\"})[0].get(\"href\").split(\"#\")[0]\n",
    "    if real_link == link:\n",
    "        real_link = None\n",
    "\n",
    "    wiki_content_links = set()\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        if link[\"href\"] == \"#cite_ref-1\":\n",
    "            break\n",
    "        clean_link = link[\"href\"]\n",
    "        clean_link = urllib.parse.unquote(clean_link)\n",
    "        if clean_link.startswith(\"/wiki/\"):\n",
    "            wiki_link = clean_link[6:]\n",
    "            if any(x in wiki_link for x in blocklist):\n",
    "                continue\n",
    "            wiki_content_links.add(clean_link)\n",
    "\n",
    "    if get_text:\n",
    "        # todo - clean this text\n",
    "        words = soup.find_all('p')\n",
    "        return wiki_content_links, real_link, words\n",
    "\n",
    "    return wiki_content_links, real_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://en.wikipedia.org/wiki/Optimal_control_theory\"\n",
    "l, real_link = parse_wiki_link(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserHistory:\n",
    "    def __init__(self, user_history):\n",
    "        self.user_history = user_history\n",
    "        # user_vists is a list of links in chronological order ascending\n",
    "        # user_vists[-1] is the current page\n",
    "        self.outgoing_links = Counter()\n",
    "        #self.ingoing_links = set()\n",
    "        self.words = []\n",
    "        for link in user_history:\n",
    "            results, real_link, words = parse_wiki_link(link, get_text=True)\n",
    "            self.words.extend(words)\n",
    "            self.outgoing_links.update(results)\n",
    "            #self.ingoing_links.update(parse_wiki_ingoing(link))\n",
    "        self.already_visited_pages = {link.split(\"wikipedia.org\")[1] for link in user_history}\n",
    "\n",
    "        # remove self-loops\n",
    "        for page in self.already_visited_pages:\n",
    "            if page in self.outgoing_links:\n",
    "                del self.outgoing_links[page]\n",
    "        #self.ingoing_links -= already_visited_pages\n",
    "        \n",
    "        # self.outgoing_text\n",
    "\n",
    "        outgoing_links_list = list(self.outgoing_links.values())\n",
    "        self.mean = np.average(outgoing_links_list)\n",
    "        self.std = np.std(outgoing_links_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_prefix(suffix):\n",
    "    # suffix is '/wiki/<article title>'\n",
    "    return \"https://en.wikipedia.org/\"+suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    def __init__(self, fetch_fn):\n",
    "        self.dict = dict()\n",
    "        self.fetch_fn = fetch_fn\n",
    "\n",
    "    def __call__(self, key, args):\n",
    "        if key in self.dict:\n",
    "            return self.dict[key]\n",
    "        result = self.fetch_fn(args)\n",
    "        self.dict[key] = result\n",
    "        return result\n",
    "\n",
    "def linkcount_fetch(wiki_page):\n",
    "    # this is so damn slow\n",
    "    link = f\"https://linkcount.toolforge.org/api/?page={wiki_page}&project=en.wikipedia.org\"\n",
    "    r = requests.get(link).json()\n",
    "    return r[\"wikilinks\"][\"all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_link_similarity(user_history, target):\n",
    "    # user_history  \n",
    "    #   incorporate idf (just hyperlinks) -> scrape target/what_links_here (expensive)\n",
    "    #   or sample 10000 pages and count link frequency and store it somewhere else                       \n",
    "    #   incorporate ingoing recommendations\n",
    "    # return score(target | user_history)\n",
    "\n",
    "    # how many times does target appear in self.outgoing_links\n",
    "    z_score = (user_history.outgoing_links[target]-user_history.mean)/user_history.std\n",
    "    return .5 * (math.erf(z_score / 2 ** .5) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_link_text_similarity(user_history, target):\n",
    "    # user_history  \n",
    "    #   incorporate idf (text)\n",
    "    #   incorporate ingoing recommendations\n",
    "    # return score(target | user_history)\n",
    "\n",
    "    # references in div class = reflist\n",
    "    \n",
    "    target = link_clean(target)\n",
    "    words = user_history.words\n",
    "    total = 0\n",
    "    for i in words:\n",
    "        i = str(i)\n",
    "        i = i.lower()\n",
    "        total += i.count(target)\n",
    "    return total\n",
    "\n",
    "def link_clean(target):\n",
    "    title = target.lower()\n",
    "    title = title[6:]\n",
    "    title = title.replace(\"_\", \" \")\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_coupling_similarity(user_history, target, cache, doc_freq_cache):\n",
    "    # user_history  \n",
    "    #   need to download target and scrape it's links\n",
    "    # pages are similar if their outgoing (ingoing) links have overlap\n",
    "    if target in cache:\n",
    "        results, real_link = cache[target]\n",
    "    else:\n",
    "        results, real_link = parse_wiki_link(target)\n",
    "        # TODO swap to MediaWiki API\n",
    "        cache[target] = [results, real_link]\n",
    "    if real_link is not None:\n",
    "        # this is a redirect link\n",
    "        if \"/wiki\" + real_link.split(\"/wiki\")[1] in user_history.already_visited_pages:\n",
    "            # already been to this page, don't re-recommend\n",
    "            # unless we want to in some cases?\n",
    "            return -100\n",
    "\n",
    "    #doc_freq = doc_freq_cache()\n",
    "    target_outgoing = Counter(results)\n",
    "\n",
    "    score = 0\n",
    "    doc_len = sum(v for v in user_history.outgoing_links.values())\n",
    "    k1 = 0.5\n",
    "    k3 = 0.5\n",
    "    b = 0.9\n",
    "    avg_doc_len = 50 #?\n",
    "    for link, count in target_outgoing.items():\n",
    "        query_count = user_history.outgoing_links[link]\n",
    "        if count == 0 or query_count == 0:\n",
    "            continue\n",
    "        page_name = link.split(\"/wiki/\")[1]\n",
    "        doc_freq = 100 #doc_freq_cache(page_name, page_name)\n",
    "\n",
    "        norm_qtf = (k3+1)*query_count / (k3 + query_count)\n",
    "        norm_tf = count * (k1 + 1) / (count + k1*((1-b)+b*(doc_len/avg_doc_len)))\n",
    "        tf = norm_tf * norm_qtf\n",
    "\n",
    "        num_links_on_wiki = 1e7\n",
    "        idf = np.log(num_links_on_wiki / (doc_freq+1))\n",
    "        score += tf * idf\n",
    "    #union = sum(v for v in target_outgoing.values()) + sum(v for v in user_history.outgoing_links.values())\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_freq_cache = Cache(linkcount_fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = \"https://en.wikipedia.org/wiki/Hamilton–Jacobi–Bellman_equation\"\n",
    "link2 = \"https://en.wikipedia.org/wiki/Value_function\"\n",
    "link3 = \"https://en.wikipedia.org/wiki/Optimal_control\"\n",
    "user_history = UserHistory([link1, link2, link3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = \"https://en.wikipedia.org/wiki/Bitcoin\"\n",
    "link2 = \"https://en.wikipedia.org/wiki/Lightning_Network\"\n",
    "user_history = UserHistory([link1, link2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_outgoing_scores_baseline(user_history):\n",
    "    # composite score_link_similarity and score_link_text_similarity\n",
    "    # (todo: this filters scores, will do re-ranking with coupling similarity, re-ranking with deeper searches, etc)\n",
    "    weight = 0.01 # to be tuned\n",
    "    outgoing_scores = dict()\n",
    "    for link in user_history.outgoing_links:\n",
    "        outgoing_scores[link] = score_link_similarity(user_history, link) + weight * score_link_text_similarity(user_history, link)\n",
    "    return outgoing_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_scores = compute_outgoing_scores_baseline(user_history)\n",
    "sorted_baseline_scores = [(k, v) for k, v in sorted(baseline_scores.items(), reverse=True, key=lambda item: item[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_coupling(user_history, baseline_scores, num_rerank):\n",
    "    new_rankings = dict()\n",
    "    for target, score in baseline_scores[:num_rerank]:\n",
    "        new_rankings[target] = score_coupling_similarity(user_history, wiki_prefix(target), cache, doc_freq_cache)\n",
    "    return new_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = rerank_with_coupling(user_history, sorted_baseline_scores, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/wiki/Dynamic_programming', 158.8045786822883),\n",
       " ('/wiki/Bellman_equation', 145.58730318947676),\n",
       " ('/wiki/Richard_Bellman', 135.32911922490658),\n",
       " ('/wiki/Dimitri_Bertsekas', 124.28184418613871),\n",
       " ('/wiki/Control_theory', 122.90093480629272),\n",
       " ('/wiki/Differential_equation', 120.13911604660075),\n",
       " ('/wiki/Objective_function', 103.56820348844892),\n",
       " ('/wiki/Hamiltonian_(control_theory)', 85.61638155045111),\n",
       " ('/wiki/Rudolf_E._Kálmán', 64.90274085276133),\n",
       " ('/wiki/Dynamical_system', 49.71273767445548),\n",
       " (\"/wiki/Pontryagin's_maximum_principle\", 37.87637156148989),\n",
       " ('/wiki/Viscosity_solution', 37.28455325584161),\n",
       " ('/wiki/Partial_differential_equation', 27.61818759691971),\n",
       " ('/wiki/Riccati_equation', 13.809093798459855),\n",
       " ('/wiki/Control_(optimal_control_theory)', 13.809093798459855)]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v) for k, v in sorted(results.items(), reverse=True, key=lambda item: item[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(ranks):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_history(user_history):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7fe94ad52fb42cd2c8480166949ec48c6429ac5eb7e0959789098eed3674765"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('ml_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
