{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import numpy as np\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import string\n",
    "#nltk.download()\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocklist = [\n",
    "    \"Main_Page\",\n",
    "    \"Help:\",\n",
    "    \"Special:\",\n",
    "    \"Portal:\",\n",
    "    \"Talk:\",\n",
    "    \"Template:\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_pipeline(words, ngram_size=1):\n",
    "    tokens = nltk.tokenize.word_tokenize(words)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    words = [w for w in words if not (w in stop_words)]\n",
    "    words = nltk.ngrams(words, ngram_size)\n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wiki_link(link, get_text=False):\n",
    "    r = requests.get(link)\n",
    "    \n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    # jank way to figure out redirect links\n",
    "    real_link = soup.find_all('link', {\"rel\" : \"canonical\"})[0].get(\"href\").split(\"#\")[0]\n",
    "    if real_link == link:\n",
    "        real_link = None\n",
    "\n",
    "    wiki_content_links = set()\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        if link[\"href\"] == \"#cite_ref-1\":\n",
    "            break\n",
    "        clean_link = link[\"href\"]\n",
    "        clean_link = urllib.parse.unquote(clean_link)\n",
    "        if clean_link.startswith(\"/wiki/\"):\n",
    "            wiki_link = clean_link[6:]\n",
    "            if any(x in wiki_link for x in blocklist):\n",
    "                continue\n",
    "            wiki_content_links.add(clean_link)\n",
    "\n",
    "    if get_text:\n",
    "        # todo - clean this text\n",
    "        words = soup.find_all('p')\n",
    "        return wiki_content_links, real_link, words\n",
    "\n",
    "    return wiki_content_links, real_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wiki_api(link, get_text=False):\n",
    "    S = requests.Session()\n",
    "\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "    PARAMS = {\n",
    "        \"action\": \"parse\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"links|properties\",\n",
    "        \"redirects\": \"\"\n",
    "    }\n",
    "    PARAMS[\"page\"] = link\n",
    "    if get_text:\n",
    "        PARAMS[\"prop\"] += \"|wikitext\"\n",
    "\n",
    "    R = S.get(url=URL, params=PARAMS)\n",
    "    DATA = R.json()\n",
    "\n",
    "    if \"parse\" not in DATA.keys():\n",
    "        return None\n",
    "    parse_links = DATA[\"parse\"][\"links\"]\n",
    "    pageid = DATA[\"parse\"][\"pageid\"]\n",
    "    redirect_list = DATA[\"parse\"][\"redirects\"]\n",
    "    if len(redirect_list) > 0:\n",
    "        redirect = redirect_list[0]['to']\n",
    "    else:\n",
    "        redirect = None\n",
    "    links = []\n",
    "    for l in parse_links:\n",
    "        #if l['*'].\n",
    "        if any(bad_prefix in l['*'] for bad_prefix in blocklist):\n",
    "            continue\n",
    "        links.append(l['*'])\n",
    "\n",
    "    if get_text:\n",
    "        words = DATA[\"parse\"][\"wikitext\"][\"*\"]\n",
    "        words = nltk_pipeline(words)\n",
    "        return links, pageid, redirect, words\n",
    "    return links, pageid, redirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserHistory:\n",
    "    def __init__(self, user_history):\n",
    "        self.user_history = user_history\n",
    "        self.already_visited_pages = set() # resolves redirects in user_history\n",
    "\n",
    "        # user_vists is a list of links in chronological order ascending\n",
    "        # user_vists[-1] is the current page\n",
    "        self.outgoing_links = Counter()\n",
    "        #self.ingoing_links = set()\n",
    "        \n",
    "        self.words = Counter()\n",
    "        for link in set(user_history):\n",
    "            out_links, pageid, redirect, words = parse_wiki_api(link, get_text=True)\n",
    "            if redirect is not None:\n",
    "                self.already_visited_pages.add(redirect)\n",
    "            else:\n",
    "                self.already_visited_pages.add(link)\n",
    "\n",
    "            self.words.update(words)\n",
    "            self.outgoing_links.update(set(out_links))\n",
    "            #self.ingoing_links.update(parse_wiki_ingoing(link))\n",
    "\n",
    "        # remove self-loops\n",
    "        for page in self.already_visited_pages:\n",
    "            if page in self.outgoing_links:\n",
    "                del self.outgoing_links[page]\n",
    "        #self.ingoing_links -= already_visited_pages\n",
    "        \n",
    "        outgoing_links_list = list(self.outgoing_links.values())\n",
    "        self.mean = np.average(outgoing_links_list)\n",
    "        self.std = np.std(outgoing_links_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_prefix(suffix):\n",
    "    # suffix is '/wiki/<article title>'\n",
    "    return \"https://en.wikipedia.org/\"+suffix\n",
    "\n",
    "def wiki_title_from_link(wiki_link):\n",
    "    # wiki_link format: \"https://en.wikipedia.org/wiki/Hamilton–Jacobi–Bellman_equation\"\n",
    "    title_unform = wiki_link[30:]\n",
    "    title = title_unform.replace(\"_\",\" \")\n",
    "    return title\n",
    "\n",
    "def wiki_link_from_title(wiki_title, link_base=\"https://en.wikipedia.org/wiki/\"):\n",
    "    # wiki title format: \"Hamilton-Jacobi-Bellman equation\"\n",
    "    title_underscore = wiki_title.replace(\" \", \"_\")\n",
    "    link = link_base + title_underscore\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    def __init__(self, fetch_fn):\n",
    "        self.dict = dict()\n",
    "        self.fetch_fn = fetch_fn\n",
    "\n",
    "    def __call__(self, key, args):\n",
    "        if key in self.dict:\n",
    "            return self.dict[key]\n",
    "        result = self.fetch_fn(args)\n",
    "        self.dict[key] = result\n",
    "        return result\n",
    "    \n",
    "    def __contains__(self, key):\n",
    "        return key in self.dict\n",
    "\n",
    "def linkcount_fetch(wiki_page):\n",
    "    # this is so damn slow\n",
    "    link = f\"https://linkcount.toolforge.org/api/?page={wiki_page}&project=en.wikipedia.org\"\n",
    "    r = requests.get(link).json()\n",
    "    return np.log(r[\"wikilinks\"][\"all\"] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_link_similarity(user_history, target):\n",
    "    # user_history  \n",
    "    #   incorporate idf (just hyperlinks) -> scrape target/what_links_here (expensive)\n",
    "    #   or sample 10000 pages and count link frequency and store it somewhere else                       \n",
    "    #   incorporate ingoing recommendations\n",
    "    # return score(target | user_history)\n",
    "\n",
    "    # how many times does target appear in self.outgoing_links\n",
    "    z_score = (user_history.outgoing_links[target]-user_history.mean)/user_history.std\n",
    "    return .5 * (math.erf(z_score / 2 ** .5) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_link_text_similarity(user_history, target):\n",
    "    # user_history  \n",
    "    #   incorporate idf (text)\n",
    "    #   incorporate ingoing recommendations\n",
    "    # return score(target | user_history)\n",
    "\n",
    "    # references in div class = reflist\n",
    "    target = nltk_pipeline(target)\n",
    "    words = user_history.words\n",
    "    total = 0\n",
    "    for term in target:\n",
    "        total += words[term]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.83765180790529 47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68.83765180790529"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_coupling_similarity(user_history, \"Pseudospectral optimal control\", cache, doc_freq_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_coupling_similarity(user_history, target, cache, doc_freq_cache):\n",
    "    # user_history  \n",
    "    #   need to download target and scrape it's links\n",
    "    # pages are similar if their outgoing (ingoing) links have overlap\n",
    "    if target in cache:\n",
    "        results = cache[target]\n",
    "    else:\n",
    "        results = parse_wiki_api(target, get_text=False)\n",
    "        # TODO swap to MediaWiki API\n",
    "        cache[target] = results\n",
    "    if results is None:\n",
    "        # likely that this link doesn't exist\n",
    "        return None\n",
    "        \n",
    "    links, pageid, redirect = results\n",
    "    if redirect is not None and redirect in user_history.already_visited_pages:\n",
    "        # don't recommend this page, a redirected variant was in the user history\n",
    "        # (only way to resolve redirects from outgoing-links is through this api call)\n",
    "        return None\n",
    "\n",
    "    # TODO: implement faster doc freq\n",
    "    #doc_freq = doc_freq_cache()\n",
    "    target_outgoing = Counter(links)\n",
    "\n",
    "    score = 0\n",
    "    doc_len = sum(v for v in user_history.outgoing_links.values())\n",
    "\n",
    "    # BM25 hyperparameters that are untuned\n",
    "    k1 = 0.5\n",
    "    k3 = 0.99\n",
    "    b = 0.9\n",
    "    avg_doc_len = 50 # estimate?\n",
    "    for link, count in target_outgoing.items():\n",
    "        query_count = user_history.outgoing_links[link]\n",
    "\n",
    "        if count == 0 or query_count == 0:\n",
    "            continue\n",
    "        #page_name = link.split(\"/wiki/\")[1]\n",
    "        doc_freq = 0.001 if link not in doc_freq_cache else doc_freq_cache(link, link)\n",
    "\n",
    "        norm_qtf = (k3+1)*query_count / (k3 + query_count)\n",
    "        norm_tf = count * (k1 + 1) / (count + k1*((1-b)+b*(doc_len/avg_doc_len)))\n",
    "        tf = norm_tf * norm_qtf\n",
    "\n",
    "        #num_links_on_wiki = 10e7\n",
    "        log_num_links_on_wiki = 6 * np.log(10)\n",
    "        idf = log_num_links_on_wiki - doc_freq\n",
    "        score += tf * idf\n",
    "    #union = sum(v for v in target_outgoing.values()) + sum(v for v in user_history.outgoing_links.values())\n",
    "    print(score, sum(v for v in target_outgoing.values()))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_outgoing_scores_baseline(user_history):\n",
    "    # composite score_link_similarity and score_link_text_similarity\n",
    "    # (todo: this filters scores, will do re-ranking with coupling similarity, re-ranking with deeper searches, etc)\n",
    "    weight = 0.005 # to be tuned\n",
    "    outgoing_scores = dict()\n",
    "    for link in user_history.outgoing_links:\n",
    "        link_sim = score_link_similarity(user_history, link)\n",
    "        text_sim = score_link_text_similarity(user_history, link)\n",
    "        outgoing_scores[link] = link_sim + weight * text_sim\n",
    "        print(link_sim, weight*text_sim, link)\n",
    "    return outgoing_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_coupling(user_history, baseline_scores, num_rerank, cache, doc_freq_cache):\n",
    "    new_rankings = {k:v for k, v in baseline_scores}\n",
    "    for target, score in baseline_scores[:num_rerank]:\n",
    "        new_score = score_coupling_similarity(user_history, target, cache, doc_freq_cache)\n",
    "        if new_score is None:\n",
    "            continue\n",
    "        print(new_score * 0.1, score, target)\n",
    "        new_rankings[target] = new_score*0.1 + score\n",
    "    return new_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_from_history(user_history):\n",
    "    baseline_scores = compute_outgoing_scores_baseline(user_history)\n",
    "    sorted_baseline_scores = [(k, v) for k, v in sorted(baseline_scores.items(), reverse=True, key=lambda item: item[1])]\n",
    "    final_results = rerank_with_coupling(user_history, sorted_baseline_scores, 8, cache, doc_freq_cache)\n",
    "    sorted_final_results = [k for k, v in sorted(final_results.items(), reverse=True, key=lambda item: item[1])]\n",
    "    return sorted_final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_history(user_history):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.948156473614706"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache = dict()\n",
    "doc_freq_cache = Cache(linkcount_fetch)\n",
    "doc_freq_cache(\"Doi (identifier)\", \"Doi (identifier)\")\n",
    "doc_freq_cache(\"ISBN (identifier)\", \"ISBN (identifier)\")\n",
    "doc_freq_cache(\"ISSN (identifier)\", \"ISSN (identifier)\")\n",
    "doc_freq_cache(\"JSTOR (identifier)\", \"JSTOR (identifier)\")\n",
    "doc_freq_cache(\"Bibcode (identifier)\", \"Bibcode (identifier)\")\n",
    "doc_freq_cache(\"Hdl (identifier)\", \"Hdl (identifier)\")\n",
    "doc_freq_cache(\"PMC (identifier)\", \"PMC (identifier)\")\n",
    "doc_freq_cache(\"PMID (identifier)\", \"PMID (identifier)\")\n",
    "doc_freq_cache(\"S2CID (identifier)\", \"S2CID (identifier)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = wiki_title_from_link(\"https://en.wikipedia.org/wiki/Hamilton–Jacobi–Bellman_equation\")\n",
    "link2 = wiki_title_from_link(\"https://en.wikipedia.org/wiki/Value_function\")\n",
    "link3 = wiki_title_from_link(\"https://en.wikipedia.org/wiki/Optimal_control\")\n",
    "user_history = UserHistory([link1, link2, link3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = wiki_title_from_link(\"https://en.wikipedia.org/wiki/Bitcoin\")\n",
    "link2 = wiki_title_from_link(\"https://en.wikipedia.org/wiki/Lightning_Network\")\n",
    "user_history = UserHistory([link1, link2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34786201669236927 0.01 Scrap\n",
      "0.34786201669236927 0.0 JSTOR (identifier)\n",
      "0.34786201669236927 0.01 José Scheinkman\n",
      "0.34786201669236927 0.25 Measurable function\n",
      "0.34786201669236927 0.005 Andreu Mas-Colell\n",
      "0.9701545203685389 0.145 Viscosity solution\n",
      "0.9701545203685389 0.96 Control theory\n",
      "0.34786201669236927 0.055 Thomas J. Sargent\n",
      "0.9701545203685389 0.28 Objective function\n",
      "0.34786201669236927 0.005 Supremum\n",
      "0.34786201669236927 0.01 Utility\n",
      "0.34786201669236927 0.015 Newton notation\n",
      "0.9701545203685389 0.145 Dynamical system\n",
      "0.34786201669236927 0.29 Indirect utility function\n",
      "0.34786201669236927 0.255 Differentiable function\n",
      "0.9999838940746322 1.025 Hamiltonian (control theory)\n",
      "0.9701545203685389 0.015 Morton Kamien\n",
      "0.34786201669236927 0.005 Parameter\n",
      "0.34786201669236927 0.39 Optimization problem\n",
      "0.34786201669236927 0.25 Lyapunov function\n",
      "0.34786201669236927 0.025 Envelope theorem\n",
      "0.34786201669236927 0.02 Michael Whinston\n",
      "0.34786201669236927 0.06 Costate variable\n",
      "0.34786201669236927 0.265 Costate equation\n",
      "0.34786201669236927 0.005 Online algorithm\n",
      "0.9701545203685389 0.01 Wendell Fleming\n",
      "0.34786201669236927 0.21 Value (mathematics)\n",
      "0.9999838940746322 0.01 Doi (identifier)\n",
      "0.9701545203685389 0.63 Partial differential equation\n",
      "0.34786201669236927 0.005 Lars Ljungqvist\n",
      "0.9999838940746322 0.0 S2CID (identifier)\n",
      "0.34786201669236927 0.14 State variable\n",
      "0.9999838940746322 0.0 ISBN (identifier)\n",
      "0.34786201669236927 0.14 Dimitri P. Bertsekas\n",
      "0.34786201669236927 0.02 John Tsitsiklis\n",
      "0.9701545203685389 0.0 Bibcode (identifier)\n",
      "0.34786201669236927 0.81 Linear-quadratic-Gaussian control\n",
      "0.34786201669236927 0.015 Little-o notation\n",
      "0.34786201669236927 1.485 Optimal control theory\n",
      "0.34786201669236927 0.17500000000000002 Bequest value\n",
      "0.9701545203685389 0.24 Dynamic programming\n",
      "0.9701545203685389 0.04 Dimitri Bertsekas\n",
      "0.34786201669236927 0.1 Principle of optimality\n",
      "0.34786201669236927 0.005 Andrei Izmailovich Subbotin\n",
      "0.34786201669236927 0.04 Proceedings of the National Academy of Sciences of the United States of America\n",
      "0.34786201669236927 0.12 Necessary and sufficient condition\n",
      "0.34786201669236927 0.01 Backward induction\n",
      "0.34786201669236927 0.06 Itô calculus\n",
      "0.9701545203685389 0.0 PMID (identifier)\n",
      "0.9701545203685389 0.075 Richard Bellman\n",
      "0.34786201669236927 0.25 Difference equation\n",
      "0.9701545203685389 0.305 Bellman equation\n",
      "0.34786201669236927 0.24 Variational problem\n",
      "0.34786201669236927 0.0 PMC (identifier)\n",
      "0.34786201669236927 0.035 Classical physics\n",
      "0.34786201669236927 0.08 Infinitesimal generator (stochastic processes)\n",
      "0.34786201669236927 0.045 Michael G. Crandall\n",
      "0.34786201669236927 0.245 Hamilton–Jacobi equation\n",
      "0.9701545203685389 0.28 Riccati equation\n",
      "0.34786201669236927 0.01 Pierre-Louis Lions\n",
      "0.34786201669236927 0.125 Minimax solution\n",
      "0.34786201669236927 0.0 Smoothness\n",
      "0.34786201669236927 0.06 Category:Articles with unsourced statements from July 2019\n",
      "0.34786201669236927 0.245 Loss function\n",
      "0.9701545203685389 0.12 Pontryagin's maximum principle\n",
      "0.34786201669236927 0.005 Subderivative\n",
      "0.34786201669236927 0.005 Wikipedia:Citation needed\n",
      "0.34786201669236927 0.195 Discrete time and continuous time\n",
      "0.34786201669236927 0.045 Artificial neural network\n",
      "0.9701545203685389 0.005 ArXiv (identifier)\n",
      "0.34786201669236927 0.245 Brachistochrone problem\n",
      "0.34786201669236927 0.245 Merton's portfolio problem\n",
      "0.9701545203685389 0.0 OCLC (identifier)\n",
      "0.34786201669236927 0.065 Stochastic\n",
      "0.9701545203685389 0.13 Rudolf E. Kálmán\n",
      "0.34786201669236927 0.16 Sum-of-squares optimization\n",
      "0.34786201669236927 0.02 Taylor expansion\n",
      "0.34786201669236927 0.01 Multilayer perceptron\n",
      "0.9701545203685389 1.485 Control (optimal control theory)\n",
      "0.34786201669236927 0.635 Elliptic partial differential equation\n",
      "0.34786201669236927 0.0 Wikipedia:Verifiability\n",
      "0.34786201669236927 0.005 Controllability\n",
      "0.34786201669236927 0.035 I. Michael Ross\n",
      "0.34786201669236927 0.03 Linear-quadratic regulator\n",
      "0.34786201669236927 0.105 Calculus of variations\n",
      "0.34786201669236927 0.87 Stochastic control\n",
      "0.34786201669236927 0.8300000000000001 Control strategy\n",
      "0.34786201669236927 0.005 Moon\n",
      "0.34786201669236927 0.095 Sufficient condition\n",
      "0.34786201669236927 0.0 Wikipedia:Please clarify\n",
      "0.34786201669236927 0.08 Boundary condition\n",
      "0.34786201669236927 0.15 Gauss pseudospectral method\n",
      "0.34786201669236927 0.01 Brachistochrone\n",
      "0.34786201669236927 0.185 Trajectory optimization\n",
      "0.34786201669236927 0.115 Arthur E. Bryson\n",
      "0.34786201669236927 0.28 Function (mathematics)\n",
      "0.34786201669236927 0.005 Spacecraft\n",
      "0.34786201669236927 0.055 Optimality criterion\n",
      "0.34786201669236927 0.005 Nancy Schwartz\n",
      "0.34786201669236927 0.005 Lagrange multiplier\n",
      "0.34786201669236927 0.03 Consistent Approximations\n",
      "0.34786201669236927 0.005 Economy\n",
      "0.34786201669236927 0.185 Continuous time\n",
      "0.34786201669236927 0.015 PID controller\n",
      "0.34786201669236927 0.015 SNOPT\n",
      "0.34786201669236927 0.0 Wayback Machine\n",
      "0.34786201669236927 0.005 Raymond Rishel\n",
      "0.34786201669236927 0.015 Evolution\n",
      "0.34786201669236927 0.045 Category:AC with 0 elements\n",
      "0.34786201669236927 0.8150000000000001 Model Predictive Control\n",
      "0.34786201669236927 0.005 Unemployment\n",
      "0.34786201669236927 0.01 TOMLAB\n",
      "0.34786201669236927 0.05 Lev Pontryagin\n",
      "0.34786201669236927 0.0 Wikipedia:Citing sources\n",
      "0.34786201669236927 0.155 Cost functional\n",
      "0.34786201669236927 0.005 Pursuit-evasion\n",
      "0.34786201669236927 1.36 DIDO (optimal control)\n",
      "0.34786201669236927 0.005 FORTRAN\n",
      "0.34786201669236927 0.0 ISSN (identifier)\n",
      "0.34786201669236927 0.03 Generalized filtering\n",
      "0.34786201669236927 0.015 Yu-Chi Ho\n",
      "0.34786201669236927 0.18 Discrete time\n",
      "0.34786201669236927 0.015 Shadow price\n",
      "0.34786201669236927 0.11 Initial condition\n",
      "0.34786201669236927 0.02 DNSS point\n",
      "0.34786201669236927 0.055 MATLAB\n",
      "0.34786201669236927 0.005 David Luenberger\n",
      "0.34786201669236927 0.11 Donald E. Kirk\n",
      "0.34786201669236927 0.09 Necessary condition\n",
      "0.34786201669236927 0.055 Edward J. McShane\n",
      "0.34786201669236927 0.08 Category:Articles needing additional references from April 2018\n",
      "0.34786201669236927 0.06 Category:Wikipedia articles needing clarification from October 2018\n",
      "0.34786201669236927 0.005 JModelica.org\n",
      "0.34786201669236927 0.01 CasADi\n",
      "0.34786201669236927 0.075 Category:Use dmy dates from April 2020\n",
      "0.34786201669236927 0.8150000000000001 Sliding mode control\n",
      "0.34786201669236927 0.0 Wikipedia:Vagueness\n",
      "0.34786201669236927 0.015 Kalman filter\n",
      "0.34786201669236927 0.05 Matrix (mathematics)\n",
      "0.34786201669236927 1.375 Pseudospectral optimal control\n",
      "0.34786201669236927 0.02 Overtaking criterion\n",
      "0.34786201669236927 0.04 Monetary policy\n",
      "0.34786201669236927 0.005 Digital data\n",
      "0.34786201669236927 0.015 Active inference\n",
      "0.34786201669236927 0.265 Boundary-value problem\n",
      "0.34786201669236927 0.025 PROPT\n",
      "0.34786201669236927 0.145 Roger W. H. Sargent\n",
      "0.34786201669236927 0.06 Constraint (mathematics)\n",
      "0.34786201669236927 0.31 Differential equation\n",
      "0.34786201669236927 0.005 ASTOS\n",
      "0.34786201669236927 0.18 Mathematical optimization\n",
      "0.34786201669236927 0.18 Hamiltonian system\n",
      "0.34786201669236927 0.01 GPOPS-II\n",
      "0.34786201669236927 0.2 Bellman pseudospectral method\n",
      "0.34786201669236927 0.13 Collocation method\n",
      "0.34786201669236927 0.03 Operations research\n",
      "0.34786201669236927 0.03 Fiscal policy\n",
      "1.5002646634349452 2.4551545203685388 Control (optimal control theory)\n",
      "9.99261834359288 2.024983894074632 Hamiltonian (control theory)\n",
      "17.28174413626929 1.9301545203685389 Control theory\n",
      "6.88377413196851 1.7228620166923694 Pseudospectral optimal control\n",
      "6.0184842917571615 1.7078620166923693 DIDO (optimal control)\n",
      "5.501783881849754 1.6001545203685388 Partial differential equation\n",
      "24.04146923387652 1.2751545203685388 Bellman equation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Bellman equation',\n",
       " 'Control theory',\n",
       " 'Hamiltonian (control theory)',\n",
       " 'Pseudospectral optimal control',\n",
       " 'DIDO (optimal control)',\n",
       " 'Partial differential equation',\n",
       " 'Control (optimal control theory)',\n",
       " 'Optimal control theory',\n",
       " 'Objective function',\n",
       " 'Riccati equation',\n",
       " 'Stochastic control',\n",
       " 'Dynamic programming',\n",
       " 'Control strategy',\n",
       " 'Model Predictive Control',\n",
       " 'Sliding mode control',\n",
       " 'Linear-quadratic-Gaussian control',\n",
       " 'Viscosity solution',\n",
       " 'Dynamical system',\n",
       " 'Rudolf E. Kálmán',\n",
       " \"Pontryagin's maximum principle\",\n",
       " 'Richard Bellman',\n",
       " 'Dimitri Bertsekas',\n",
       " 'Doi (identifier)',\n",
       " 'S2CID (identifier)',\n",
       " 'ISBN (identifier)',\n",
       " 'Morton Kamien',\n",
       " 'Elliptic partial differential equation',\n",
       " 'Wendell Fleming',\n",
       " 'ArXiv (identifier)',\n",
       " 'Bibcode (identifier)',\n",
       " 'PMID (identifier)',\n",
       " 'OCLC (identifier)',\n",
       " 'Optimization problem',\n",
       " 'Differential equation',\n",
       " 'Indirect utility function',\n",
       " 'Function (mathematics)',\n",
       " 'Costate equation',\n",
       " 'Boundary-value problem',\n",
       " 'Differentiable function',\n",
       " 'Measurable function',\n",
       " 'Lyapunov function',\n",
       " 'Difference equation',\n",
       " 'Hamilton–Jacobi equation',\n",
       " 'Loss function',\n",
       " 'Brachistochrone problem',\n",
       " \"Merton's portfolio problem\",\n",
       " 'Variational problem',\n",
       " 'Value (mathematics)',\n",
       " 'Bellman pseudospectral method',\n",
       " 'Discrete time and continuous time',\n",
       " 'Trajectory optimization',\n",
       " 'Continuous time',\n",
       " 'Discrete time',\n",
       " 'Mathematical optimization',\n",
       " 'Hamiltonian system',\n",
       " 'Bequest value',\n",
       " 'Sum-of-squares optimization',\n",
       " 'Cost functional',\n",
       " 'Gauss pseudospectral method',\n",
       " 'Roger W. H. Sargent',\n",
       " 'State variable',\n",
       " 'Dimitri P. Bertsekas',\n",
       " 'Collocation method',\n",
       " 'Minimax solution',\n",
       " 'Necessary and sufficient condition',\n",
       " 'Arthur E. Bryson',\n",
       " 'Initial condition',\n",
       " 'Donald E. Kirk',\n",
       " 'Calculus of variations',\n",
       " 'Principle of optimality',\n",
       " 'Sufficient condition',\n",
       " 'Necessary condition',\n",
       " 'Infinitesimal generator (stochastic processes)',\n",
       " 'Boundary condition',\n",
       " 'Category:Articles needing additional references from April 2018',\n",
       " 'Category:Use dmy dates from April 2020',\n",
       " 'Stochastic',\n",
       " 'Costate variable',\n",
       " 'Itô calculus',\n",
       " 'Category:Articles with unsourced statements from July 2019',\n",
       " 'Category:Wikipedia articles needing clarification from October 2018',\n",
       " 'Constraint (mathematics)',\n",
       " 'Thomas J. Sargent',\n",
       " 'Optimality criterion',\n",
       " 'MATLAB',\n",
       " 'Edward J. McShane',\n",
       " 'Lev Pontryagin',\n",
       " 'Matrix (mathematics)',\n",
       " 'Michael G. Crandall',\n",
       " 'Artificial neural network',\n",
       " 'Category:AC with 0 elements',\n",
       " 'Proceedings of the National Academy of Sciences of the United States of America',\n",
       " 'Monetary policy',\n",
       " 'Classical physics',\n",
       " 'I. Michael Ross',\n",
       " 'Linear-quadratic regulator',\n",
       " 'Consistent Approximations',\n",
       " 'Generalized filtering',\n",
       " 'Operations research',\n",
       " 'Fiscal policy',\n",
       " 'Envelope theorem',\n",
       " 'PROPT',\n",
       " 'Michael Whinston',\n",
       " 'John Tsitsiklis',\n",
       " 'Taylor expansion',\n",
       " 'DNSS point',\n",
       " 'Overtaking criterion',\n",
       " 'Newton notation',\n",
       " 'Little-o notation',\n",
       " 'PID controller',\n",
       " 'SNOPT',\n",
       " 'Evolution',\n",
       " 'Yu-Chi Ho',\n",
       " 'Shadow price',\n",
       " 'Kalman filter',\n",
       " 'Active inference',\n",
       " 'Scrap',\n",
       " 'José Scheinkman',\n",
       " 'Utility',\n",
       " 'Backward induction',\n",
       " 'Pierre-Louis Lions',\n",
       " 'Multilayer perceptron',\n",
       " 'Brachistochrone',\n",
       " 'TOMLAB',\n",
       " 'CasADi',\n",
       " 'GPOPS-II',\n",
       " 'Andreu Mas-Colell',\n",
       " 'Supremum',\n",
       " 'Parameter',\n",
       " 'Online algorithm',\n",
       " 'Lars Ljungqvist',\n",
       " 'Andrei Izmailovich Subbotin',\n",
       " 'Subderivative',\n",
       " 'Wikipedia:Citation needed',\n",
       " 'Controllability',\n",
       " 'Moon',\n",
       " 'Spacecraft',\n",
       " 'Nancy Schwartz',\n",
       " 'Lagrange multiplier',\n",
       " 'Economy',\n",
       " 'Raymond Rishel',\n",
       " 'Unemployment',\n",
       " 'Pursuit-evasion',\n",
       " 'FORTRAN',\n",
       " 'David Luenberger',\n",
       " 'JModelica.org',\n",
       " 'Digital data',\n",
       " 'ASTOS',\n",
       " 'JSTOR (identifier)',\n",
       " 'PMC (identifier)',\n",
       " 'Smoothness',\n",
       " 'Wikipedia:Verifiability',\n",
       " 'Wikipedia:Please clarify',\n",
       " 'Wayback Machine',\n",
       " 'Wikipedia:Citing sources',\n",
       " 'ISSN (identifier)',\n",
       " 'Wikipedia:Vagueness']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_from_history(user_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4,5,6][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Frank–Wolfe_algorithm'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.parse.unquote(\"https://en.wikipedia.org/wiki/Frank%E2%80%93Wolfe_algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7fe94ad52fb42cd2c8480166949ec48c6429ac5eb7e0959789098eed3674765"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('ml_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
